{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyTTg7W2tGsuWqe2Tti9m8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE2/blob/master/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**set data and model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9AgTPALBCHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQQCnKk3E6qG",
        "colab_type": "text"
      },
      "source": [
        "**set models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch,wandb,os,warnings,csv\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "num_epochs=5           #\n",
        "batch_size = 128       #\n",
        "image_size=784         #\n",
        "hidden_size=128        #\n",
        "lv_size = 48           # Latent Variable \n",
        "learning_rate=1e-4     #\n",
        "cret = nn.MSELoss()    # criterion\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size), \n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "             nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "             nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))\n",
        "\n",
        "def model_name(digit):\n",
        "  return './ae_'+str(digit)+'.pth'\n",
        "\n",
        "model = autoencoder()\n",
        "tmodel=autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])\n",
        "\n",
        "\n",
        "def save_model(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  torch.save(model.state_dict(),mn )\n",
        "  wandb.save(mn)\n",
        "  print(\"save model \"+ mn)\n",
        "\n",
        "def load_model_ifexist(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  if os.path.isfile(mn):\n",
        "    model.load_state_dict(torch.load(mn))\n",
        "    model.eval()\n",
        "  return model\n",
        "\n",
        "def train_by_digit(by_digit,dna,model,ne=num_epochs,opt=optimizer):\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[dna==by_digit]), batch_size=batch_size,shuffle=True, num_workers=6)\n",
        "  for epoch in range(ne):\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "  return loss.data"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48TVSdtDFCei",
        "colab_type": "text"
      },
      "source": [
        "**set dna**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "082e4e5e-c1db-4abf-a5d8-97ab4321fe70"
      },
      "source": [
        "\n",
        "\n",
        "def dna_init(n):\n",
        "  arr = np.zeros( n,dtype=np.int32)\n",
        "  for i in range(n):\n",
        "    arr[i]=random.randint(0,9)\n",
        "  return arr\n",
        "\n",
        "\n",
        "\n",
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "dna = dna_init(len(xtrain))\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 5 5 ... 3 1 1]\n",
            "[5 0 4 ... 5 6 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PClq81tkDu-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdecf39d-c3da-47e7-af72-ead9da528ca6"
      },
      "source": [
        "def testscore(dna,ytrain):\n",
        "  return len(dna[dna==ytrain])/len(ytrain)\n",
        "\n",
        "testscore(dna,ytrain)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09956666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}